{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "project_v4.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "9Vov-bAAz5qa",
        "8T-c0nl7wBRW"
      ],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PcuaFdKEzv0y",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "**Install requirements**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ryWt0frSztI_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip3 install 'torch==1.4.0'\n",
        "!pip3 install 'torchvision==0.5.0'\n",
        "!pip3 install 'Pillow-SIMD'\n",
        "!pip3 install 'tqdm'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ot5KOZU-zwb3",
        "colab_type": "text"
      },
      "source": [
        "**Import libraries**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FdWw9Oulzw5B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import logging\n",
        "import copy \n",
        "import sys\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Subset, DataLoader\n",
        "from torch.backends import cudnn\n",
        "from torch.autograd import Function\n",
        "\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "from torchvision.models import alexnet\n",
        "from torchvision.datasets import VisionDataset\n",
        "\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import random"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wdzn9gS6Igls",
        "colab_type": "text"
      },
      "source": [
        "####**Set Arguments**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CDPsHDf1Ikeb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "DEVICE = 'cuda' # 'cuda' or 'cpu'\n",
        "\n",
        "DATA_DIR = 'AIML_project_dataset/dataset_1_alt'\n",
        "NUM_CLASSES = 4 \n",
        "\n",
        "MOMENTUM = 0.9       # Hyperparameter for SGD, keep this at 0.9 when using SGD\n",
        "\n",
        "STEP_SIZE = 20       # How many epochs before decreasing learning rate (if using a step-down policy)\n",
        "GAMMA = 0.1          # Multiplicative factor for learning rate step-down\n",
        "\n",
        "LOG_FREQUENCY = 10\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ETuHFklY0dcp",
        "colab_type": "text"
      },
      "source": [
        "####**Define Data Preprocessing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ssupi0gL0ecs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mean = [0.485, 0.456, 0.406]\n",
        "std = [0.229, 0.224, 0.225]\n",
        " \n",
        "train_transform = transforms.Compose([transforms.Resize(256),      # Resizes short size of the PIL image to 256\n",
        "                                      transforms.CenterCrop(224),  # Crops a central square patch of the image\n",
        "                                                                  # 224 because torchvision's AlexNet needs a 224x224 input!\n",
        "                                                                  # Remember this when applying different transformations, otherwise you get an error\n",
        "                                      transforms.ToTensor(),      # Turn PIL Image to torch.Tensor\n",
        "                                      transforms.Normalize(mean, std)# Normalizes tensor with mean and standard deviation\n",
        "                                        \n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Vov-bAAz5qa",
        "colab_type": "text"
      },
      "source": [
        "####**class Quad_Reader**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0NZDA3Eiz6IN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "IMG_EXTENSIONS = [\n",
        "    '.jpg', '.JPG', '.jpeg', '.JPEG',\n",
        "    '.png', '.PNG', '.ppm', '.PPM', '.bmp', '.BMP',\n",
        "]\n",
        "\n",
        "def pil_loader(path):\n",
        "    # open path as file to avoid ResourceWarning (https://github.com/python-pillow/Pillow/issues/835)\n",
        "    with open(path, 'rb') as f:\n",
        "        img = Image.open(f)\n",
        "        return img.convert('RGB')\n",
        "\n",
        "class Quad_Reader(VisionDataset):\n",
        "  def __init__(self, root, split='train', transform=None, target_transform=None, loader=pil_loader):\n",
        "        super(Quad_Reader, self).__init__(root, transform=transform, target_transform=target_transform)\n",
        "        \n",
        "        self.transform = transform\n",
        "        self.target_transform = target_transform\n",
        "        self.loader = loader\n",
        "        self.classes, self.class_to_idx = self._find_classes(self.root)\n",
        "        self.images = self.make_dataset(root,self.class_to_idx)\n",
        "\n",
        "  def _find_classes(self, dir):\n",
        "        \n",
        "        if sys.version_info >= (3, 5):\n",
        "            # Faster and available in Python 3.5 and above\n",
        "            classes = [d.name for d in os.scandir(dir) if d.is_dir()]\n",
        "        else:\n",
        "            classes = [d for d in os.listdir(dir) if os.path.isdir(os.path.join(dir, d))]\n",
        "        classes.sort()\n",
        "        class_to_idx = {classes[i]: i for i in range(len(classes))}\n",
        "        return classes, class_to_idx\n",
        "\n",
        "  def make_dataset(self, dir, class_to_idx):\n",
        "    images = []\n",
        "    dir = os.path.expanduser(dir)\n",
        "    \n",
        "    for target in sorted(class_to_idx.keys()):\n",
        "        d = os.path.join(dir, target)\n",
        "        if not os.path.isdir(d):\n",
        "            continue\n",
        "        for root, dirs, _ in sorted(os.walk(d)):\n",
        "            for i in sorted(dirs):\n",
        "                path = os.path.join(root, i)\n",
        "                item = (path, class_to_idx[target])\n",
        "                images.append(item)\n",
        "\n",
        "    return images  # contiene i path delle cartelle contenenti le quaterne. Ogni path è associato ad un'etichetta che indica la posizione dell'odd\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "\n",
        "        quad = []\n",
        "        sample_dir, label = self.images[index]\n",
        "        for img in sorted(os.listdir(sample_dir)):\n",
        "          image_path = os.path.join(sample_dir, img) \n",
        "          quad.append( self.loader(image_path))\n",
        "\n",
        "        # Applies preprocessing when accessing the image\n",
        "        if self.transform is not None:\n",
        "          for i in range(4):\n",
        "              quad[i] = self.transform(quad[i])\n",
        "        if self.target_transform is not None:\n",
        "            label = self.target_transform(label)\n",
        "\n",
        "        return quad, label  \n",
        "\n",
        "  def __len__(self):\n",
        "        length = len(self.images)\n",
        "        return length  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8T-c0nl7wBRW",
        "colab_type": "text"
      },
      "source": [
        "####**OOONet**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zYoJ1c_gwBtT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ConcatLayer(Function):\n",
        "    @staticmethod\n",
        "    def forward(ctx, fc6_1 ,fc6_2, fc6_3 ,fc6_4):\n",
        "        #print(fc6_1.shape,fc6_2.shape,fc6_3.shape,fc6_4.shape )\n",
        "        concatenation = torch.stack([fc6_1, fc6_2,fc6_3,fc6_4], dim=1) # esempio (3,4) (3,4)  ---> ( 2, 3, 4 )  oppure ( 4096 )( 4096 ) --> (2,4096)\n",
        "        #print(\"out concatenation\")\n",
        "        #print(concatenation.shape)\n",
        "        return concatenation\n",
        "        \n",
        "    @staticmethod\n",
        "    def backward(ctx, grad_output):\n",
        "        #print(\"backward concatenation\")\n",
        "        grads = torch.unbind(grad_output,dim=1)\n",
        "        \"\"\"for t in grads:\n",
        "         print(t.shape)\"\"\"\n",
        "        #print(grad_output.shape)\n",
        "        return grads\n",
        "\n",
        "\n",
        "class OOONet(nn.Module):\n",
        "\n",
        "    def __init__(self, num_classes=1000):\n",
        "        super(OOONet, self).__init__()\n",
        "        \n",
        "        self.branch1_1 = nn.Sequential(\n",
        "            nn.Conv2d(3, 64, kernel_size=11, stride=4, padding=2),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "            nn.Conv2d(64, 192, kernel_size=5, padding=2),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "            nn.Conv2d(192, 384, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(384, 256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "            nn.AdaptiveAvgPool2d((6, 6)),           \n",
        "        )\n",
        "        self.branch1_2 = nn.Sequential(\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(256 * 6 * 6, 4096),                   #FC 6 \n",
        "            nn.ReLU(inplace=True),\n",
        "        )\n",
        "        self.branch2_1 = nn.Sequential(\n",
        "            nn.Conv2d(3, 64, kernel_size=11, stride=4, padding=2),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "            nn.Conv2d(64, 192, kernel_size=5, padding=2),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "            nn.Conv2d(192, 384, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(384, 256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "            nn.AdaptiveAvgPool2d((6, 6)),\n",
        "        )\n",
        "        self.branch2_2 = nn.Sequential(\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(256 * 6 * 6, 4096),                   #FC 6 \n",
        "            nn.ReLU(inplace=True),\n",
        "        )\n",
        "        self.branch3_1 = nn.Sequential(\n",
        "            nn.Conv2d(3, 64, kernel_size=11, stride=4, padding=2),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "            nn.Conv2d(64, 192, kernel_size=5, padding=2),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "            nn.Conv2d(192, 384, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(384, 256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "            nn.AdaptiveAvgPool2d((6, 6)),   \n",
        "        )\n",
        "        self.branch3_2 = nn.Sequential(\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(256 * 6 * 6, 4096),                   #FC 6 \n",
        "            nn.ReLU(inplace=True),\n",
        "        )\n",
        "        self.branch4_1 = nn.Sequential(\n",
        "            nn.Conv2d(3, 64, kernel_size=11, stride=4, padding=2),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "            nn.Conv2d(64, 192, kernel_size=5, padding=2),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "            nn.Conv2d(192, 384, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(384, 256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(256, 256, kernel_size=3, padding=1),  #CONV 5 \n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "            nn.AdaptiveAvgPool2d((6, 6)),\n",
        "               \n",
        "        )\n",
        "        self.branch4_2 = nn.Sequential(\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(256 * 6 * 6, 4096),                   #FC 6 \n",
        "            nn.ReLU(inplace=True),\n",
        "        )        \n",
        "        #self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n",
        "     \n",
        "        #Livelli di fusione!!!!!!!\n",
        "        self.concatLayer = ConcatLayer()\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(4096*4,4096),            \n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(4096, NUM_CLASSES),\n",
        "        )\n",
        "        \n",
        "    \n",
        "    def forward(self, x):\n",
        "        # X è un vettore di 4 immagini.\n",
        "        x0 = self.branch1_1(x[0])\n",
        "        #x0 = self.avgpool(x0)\n",
        "        x0 = torch.flatten(x0, 1)\n",
        "        output_branch1 = self.branch1_2(x0)\n",
        "\n",
        "        x1 = self.branch2_1(x[1])\n",
        "        #x1 = self.avgpool(x1)\n",
        "        x1 = torch.flatten(x1, 1)\n",
        "        output_branch2 = self.branch2_2(x1)\n",
        "\n",
        "        x2 = self.branch3_1(x[2])\n",
        "        #x2 = self.avgpool(x2)\n",
        "        x2 = torch.flatten(x2, 1)\n",
        "        output_branch3 = self.branch3_2(x2)\n",
        "\n",
        "        x3 = self.branch4_1(x[3])\n",
        "        #x3 = self.avgpool(x3)\n",
        "        x3 = torch.flatten(x3, 1)\n",
        "        output_branch4 = self.branch4_2(x3)\n",
        "\n",
        "        out = self.concatLayer.apply(output_branch1,output_branch2,output_branch3,output_branch4) \n",
        "        out = torch.flatten(out,1)\n",
        "        #print(\"out flatten\")\n",
        "        #print(out.shape)\n",
        "        out = self.classifier(out)\n",
        "      \n",
        "        \n",
        "        return out\n",
        "\n",
        "def buildO3Net ():\n",
        "\n",
        "    model = alexnet(pretrained=True)\n",
        "\n",
        "    net =  OOONet()\n",
        "    \n",
        "    #DEEP COPY FEATURES OF BRANCH 1\n",
        "\n",
        "    net.branch1_1[0].weight.data = copy.deepcopy(model.features[0].weight.data)\n",
        "    net.branch1_1[0].bias.data = copy.deepcopy(model.features[0].bias.data)   \n",
        "    net.branch1_1[3].weight.data = copy.deepcopy(model.features[3].weight.data)\n",
        "    net.branch1_1[3].bias.data = copy.deepcopy(model.features[3].bias.data)\n",
        "    net.branch1_1[6].weight.data = copy.deepcopy(model.features[6].weight.data)\n",
        "    net.branch1_1[6].bias.data = copy.deepcopy(model.features[6].bias.data)\n",
        "    net.branch1_1[8].weight.data = copy.deepcopy(model.features[8].weight.data)\n",
        "    net.branch1_1[8].bias.data = copy.deepcopy(model.features[8].bias.data)\n",
        "    net.branch1_1[10].weight.data = copy.deepcopy(model.features[10].weight.data)\n",
        "    net.branch1_1[10].bias.data = copy.deepcopy(model.features[10].bias.data)\n",
        "    net.branch1_2[1].weight.data = copy.deepcopy(model.classifier[1].weight.data)\n",
        "    net.branch1_2[1].bias.data = copy.deepcopy(model.classifier[1].bias.data)\n",
        "\n",
        "\n",
        "    #DEEP COPY FEATURES OF BRANCH 2\n",
        "\n",
        "    net.branch2_1[0].weight.data = copy.deepcopy(model.features[0].weight.data)\n",
        "    net.branch2_1[0].bias.data = copy.deepcopy(model.features[0].bias.data)   \n",
        "    net.branch2_1[3].weight.data = copy.deepcopy(model.features[3].weight.data)\n",
        "    net.branch2_1[3].bias.data = copy.deepcopy(model.features[3].bias.data)\n",
        "    net.branch2_1[6].weight.data = copy.deepcopy(model.features[6].weight.data)\n",
        "    net.branch2_1[6].bias.data = copy.deepcopy(model.features[6].bias.data)\n",
        "    net.branch2_1[8].weight.data = copy.deepcopy(model.features[8].weight.data)\n",
        "    net.branch2_1[8].bias.data = copy.deepcopy(model.features[8].bias.data)\n",
        "    net.branch2_1[10].weight.data = copy.deepcopy(model.features[10].weight.data)\n",
        "    net.branch2_1[10].bias.data = copy.deepcopy(model.features[10].bias.data)\n",
        "    net.branch2_2[1].weight.data = copy.deepcopy(model.classifier[1].weight.data)\n",
        "    net.branch2_2[1].bias.data = copy.deepcopy(model.classifier[1].bias.data)\n",
        "\n",
        "    #DEEP COPY FEATURES OF BRANCH 3\n",
        "\n",
        "    net.branch3_1[0].weight.data = copy.deepcopy(model.features[0].weight.data)\n",
        "    net.branch3_1[0].bias.data = copy.deepcopy(model.features[0].bias.data)   \n",
        "    net.branch3_1[3].weight.data = copy.deepcopy(model.features[3].weight.data)\n",
        "    net.branch3_1[3].bias.data = copy.deepcopy(model.features[3].bias.data)\n",
        "    net.branch3_1[6].weight.data = copy.deepcopy(model.features[6].weight.data)\n",
        "    net.branch3_1[6].bias.data = copy.deepcopy(model.features[6].bias.data)\n",
        "    net.branch3_1[8].weight.data = copy.deepcopy(model.features[8].weight.data)\n",
        "    net.branch3_1[8].bias.data = copy.deepcopy(model.features[8].bias.data)\n",
        "    net.branch3_1[10].weight.data = copy.deepcopy(model.features[10].weight.data)\n",
        "    net.branch3_1[10].bias.data = copy.deepcopy(model.features[10].bias.data)\n",
        "    net.branch3_2[1].weight.data = copy.deepcopy(model.classifier[1].weight.data)\n",
        "    net.branch3_2[1].bias.data = copy.deepcopy(model.classifier[1].bias.data)\n",
        "\n",
        "    #DEEP COPY FEATURES OF BRANCH 4\n",
        "\n",
        "    net.branch4_1[0].weight.data = copy.deepcopy(model.features[0].weight.data)\n",
        "    net.branch4_1[0].bias.data = copy.deepcopy(model.features[0].bias.data)   \n",
        "    net.branch4_1[3].weight.data = copy.deepcopy(model.features[3].weight.data)\n",
        "    net.branch4_1[3].bias.data = copy.deepcopy(model.features[3].bias.data)\n",
        "    net.branch4_1[6].weight.data = copy.deepcopy(model.features[6].weight.data)\n",
        "    net.branch4_1[6].bias.data = copy.deepcopy(model.features[6].bias.data)\n",
        "    net.branch4_1[8].weight.data = copy.deepcopy(model.features[8].weight.data)\n",
        "    net.branch4_1[8].bias.data = copy.deepcopy(model.features[8].bias.data)\n",
        "    net.branch4_1[10].weight.data = copy.deepcopy(model.features[10].weight.data)\n",
        "    net.branch4_1[10].bias.data = copy.deepcopy(model.features[10].bias.data)\n",
        "    net.branch4_2[1].weight.data = copy.deepcopy(model.classifier[1].weight.data)\n",
        "    net.branch4_2[1].bias.data = copy.deepcopy(model.classifier[1].bias.data)\n",
        "\n",
        "    return net\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TbEcuheuxq7N",
        "colab_type": "text"
      },
      "source": [
        "####**Prepare Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BRfhXYeuxrsI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Clone github repository with data\n",
        "if not os.path.isdir('./AIML_project_dataset'):\n",
        "  !git clone https://github.com/rebeccapelaca/AIML_project_dataset.git\n",
        "\n",
        "dataset = Quad_Reader(DATA_DIR, transform=train_transform)\n",
        "print('Dataset: {}'.format(len(dataset)))\n",
        "\n",
        "# 66 - 17 - 17\n",
        "\n",
        "train_indexes = [idx for idx in range(len(dataset)) if (idx % 3) != 0]\n",
        "val_indexes = [idx for idx in range(len(dataset)) if (idx % 3) == 0 and (idx % 6) != 0]\n",
        "test_indexes = [idx for idx in range(len(dataset)) if not (idx % 6)]\n",
        "\n",
        "train_dataset = Subset(dataset, train_indexes)\n",
        "val_dataset = Subset(dataset, val_indexes)\n",
        "test_dataset = Subset(dataset, test_indexes)\n",
        "\n",
        "print('Training Dataset: {}'.format(len(train_dataset)))\n",
        "print('Validation Dataset: {}'.format(len(val_dataset)))\n",
        "print('Test Dataset: {}'.format(len(test_dataset)))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y-o71raqSCjo",
        "colab_type": "text"
      },
      "source": [
        "###**Random Search**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HM7Ak0tg6cHC",
        "colab_type": "text"
      },
      "source": [
        "**Plots**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zQ2UCs74jDkr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def plot_graph(epoches ,val_data , train_data, lr,wd,dp ,xlabel ,ylabel, legend1 = \"val\", legend2=\"train\"):\n",
        "  \n",
        "  epoches = range(epoches)\n",
        "  plt.plot(epoches,val_data,label=legend1)\n",
        "  plt.plot(epoches,train_data,label=legend2)\n",
        "  \n",
        "  plt.title('Hyperparameters - LR={} WD={} DP={}'.format(lr,wd,dp))\n",
        "  plt.xlabel(xlabel)\n",
        "  plt.ylabel(ylabel)\n",
        "  plt.legend()\n",
        "  plt.show() \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IZm4NXAg6iB9",
        "colab_type": "text"
      },
      "source": [
        "**Random Search**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZJrUzacSSIRD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#parametri\n",
        "best_LR = 0\n",
        "best_BS = 0\n",
        "best_WD = 0\n",
        "best_DP = 0\n",
        "bss = [128,256]\n",
        "num_iters = 3\n",
        "best_acc = 0.0\n",
        "\n",
        "for bs in bss:\n",
        "  train_dataloader = DataLoader(dataset=train_dataset, batch_size=bs, shuffle=True, num_workers=4, drop_last=True)\n",
        "  val_dataloader = DataLoader(dataset=val_dataset, batch_size=bs, shuffle=True, num_workers=4, drop_last=True)\n",
        "  \n",
        "  for iteration in range(num_iters):\n",
        "\n",
        "    # Pick random hyperparameters in a specified range\n",
        "    mod = random.randint(1,9)\n",
        "    lr = mod*10**(-random.randint(2,4)) #learning rate \n",
        "    wd = 10**(-random.randint(4,6)) #weight_decay\n",
        "    dp = random.uniform(0.2,0.5)    #dropout probability\n",
        "\n",
        "    net = buildO3Net()\n",
        "    net.to(DEVICE)\n",
        "\n",
        "    net.branch1_2[0] = nn.Dropout(dp)\n",
        "    net.branch2_2[0] = nn.Dropout(dp)\n",
        "    net.branch3_2[0] = nn.Dropout(dp)\n",
        "    net.branch4_2[0] = nn.Dropout(dp)\n",
        "    net.classifier[0] = nn.Dropout(dp)  \n",
        "\n",
        "    criterion = nn.CrossEntropyLoss() \n",
        "    parameters_to_optimize = net.parameters()\n",
        "    optimizer = optim.SGD(parameters_to_optimize, lr=lr, momentum=MOMENTUM, weight_decay=wd)\n",
        "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=STEP_SIZE, gamma=GAMMA)\n",
        "\n",
        "    num_epochs = 30\n",
        "\n",
        "    current_step=0\n",
        "    tmp_accuracy = 0.0\n",
        "    current_step = 0\n",
        "\n",
        "    val_acc_history_1 = []\n",
        "    val_loss_history_1 = []\n",
        "    train_acc_history_1 = []\n",
        "    train_loss_history_1 = []\n",
        "    test_accuracy_local = 0 # best accuracy for one set of parameters\n",
        "    lossNan = False\n",
        "    for epoch in range(num_epochs):\n",
        "      \n",
        "      running_loss_1 = 0.0\n",
        "      running_corrects_1 = 0\n",
        "      print('Starting epoch {}/{}, LR = {}'.format(epoch+1, num_epochs, scheduler.get_lr()))\n",
        "\n",
        "      for images, labels in train_dataloader:\n",
        "\n",
        "        for i in range(4):\n",
        "          images[i] = images[i].to(DEVICE)\n",
        "        \n",
        "        labels = labels.to(DEVICE)\n",
        "\n",
        "        net.train() \n",
        "\n",
        "        optimizer.zero_grad() # Zero-ing the gradients\n",
        "        \n",
        "        outputs = net(images)\n",
        "        _, preds = torch.max(outputs.data, 1)\n",
        "\n",
        "        loss = criterion(outputs, labels)\n",
        "        print(\"loss:{}\".format(loss.item()))\n",
        "\n",
        "        if np.isnan(loss.item()):\n",
        "          lossNan = True\n",
        "          print(\"Early stopping: loss NaN\")\n",
        "          break\n",
        "\n",
        "        loss.backward()  \n",
        "        optimizer.step() \n",
        "\n",
        "        running_loss_1 += loss.item() \n",
        "        running_corrects_1 += torch.sum(preds == labels.data)\n",
        "                                        \n",
        "        current_step += 1\n",
        "      \n",
        "      #statistiche\n",
        "      epoch_loss_1 = running_loss_1 / len(train_dataloader)\n",
        "      epoch_acc_1 = running_corrects_1 / float(len(train_dataloader.dataset))\n",
        "      train_loss_history_1.append(epoch_loss_1)              \n",
        "      train_acc_history_1.append(epoch_acc_1)\n",
        "\n",
        "      if lossNan:\n",
        "        break\n",
        "\n",
        "      net.to(DEVICE)\n",
        "      net.train(False) # Set Network to evaluation mode\n",
        "\n",
        "      running_corrects_1 = 0.0\n",
        "      running_loss_1 = 0.0\n",
        "      \n",
        "      for images, labels in tqdm(val_dataloader):\n",
        "        \n",
        "        for i in range(4):\n",
        "          images[i] = images[i].to(DEVICE)\n",
        "\n",
        "        labels = labels.to(DEVICE)\n",
        "        # Forward Pass\n",
        "        outputs = net(images)\n",
        "        loss = criterion(outputs,labels)\n",
        "        _, preds = torch.max(outputs.data, 1)\n",
        "        \n",
        "        # statistics\n",
        "        running_loss_1 += loss.item() \n",
        "        running_corrects_1 += torch.sum(preds == labels.data).data.item()\n",
        "\n",
        "      # Calculate Accuracy\n",
        "      test_accuracy = running_corrects_1 / float(len(val_dataloader.dataset))  \n",
        "      print('Test Accuracy: {}'.format(test_accuracy))\n",
        "      if test_accuracy > test_accuracy_local:\n",
        "        test_accuracy_local = test_accuracy\n",
        "\n",
        "      \n",
        "      epoch_loss_1 = running_loss_1 / len(val_dataloader)           \n",
        "  \n",
        "      val_loss_history_1.append(epoch_loss_1)              \n",
        "      val_acc_history_1.append(test_accuracy)\n",
        "\n",
        "      # Step the scheduler\n",
        "      scheduler.step() \n",
        "\n",
        "    if lossNan == False:\n",
        "      if test_accuracy_local > best_acc:\n",
        "        best_acc = test_accuracy_local \n",
        "        best_LR = lr\n",
        "        best_WD = wd\n",
        "        best_DP = dp\n",
        "        best_BS = bs\n",
        "\n",
        "      #plot graphs\n",
        "      plot_graph(num_epochs , val_loss_history_1 ,train_loss_history_1 ,lr,wd,dp ,\"epochs\" ,\"loss\", \"val\",\"train\")\n",
        "      plot_graph(num_epochs , val_acc_history_1, train_acc_history_1  ,lr,wd,dp ,\"epochs\" ,\"accuracy\", \"val\",\"train\")\n",
        "      \n",
        "print('find_best_HyperParam_3B COMPLETE ')\n",
        "print(\"Best hyperparameters: best accuracy:{}, best_LR:{}, best_WD:{}, best_DP:{}, best_BS:{}\".format(best_acc,best_LR,best_WD,best_DP,best_BS))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OvLJCfwJyTGb",
        "colab_type": "text"
      },
      "source": [
        "####**Train**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UucjCgoqyVgp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"Best hyperparameters: best accuracy:{}, best_LR:{}, best_WD:{}, best_DP:{}, best_BS:{}\".format(best_acc,best_LR,best_WD,best_DP, best_BS))\n",
        "\"\"\"best_LR = 0.001\n",
        "best_WD = 1e-06\n",
        "best_DP = 0.255889\n",
        "best_BS = 128\n",
        "best_acc=0\"\"\"\n",
        "net = buildO3Net()\n",
        "net.to(DEVICE)\n",
        "criterion = nn.CrossEntropyLoss() \n",
        "parameters_to_optimize = net.parameters()\n",
        "optimizer = optim.SGD(parameters_to_optimize, lr=best_LR, momentum=MOMENTUM, weight_decay=best_WD)\n",
        "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=STEP_SIZE, gamma=GAMMA)\n",
        "\n",
        "net.branch1_2[0] = nn.Dropout(best_DP)\n",
        "net.branch2_2[0] = nn.Dropout(best_DP)\n",
        "net.branch3_2[0] = nn.Dropout(best_DP)\n",
        "net.branch4_2[0] = nn.Dropout(best_DP)\n",
        "net.classifier[0] = nn.Dropout(best_DP)\n",
        "\n",
        "# TODO (da migliorare) training su training + validation\n",
        "train_indexes = [idx for idx in range(len(dataset)) if (idx % 6) != 0]\n",
        "train_dataset = Subset(dataset, train_indexes)\n",
        "train_dataloader = DataLoader(dataset=train_dataset, batch_size=best_BS, shuffle=True, num_workers=4, drop_last=True)\n",
        "\n",
        "num_epochs = 30\n",
        "current_step=0\n",
        "for epoch in range(num_epochs):\n",
        "    print('Starting epoch {}/{}, LR = {}'.format(epoch+1, num_epochs, scheduler.get_lr()))\n",
        "\n",
        "    for images, labels in train_dataloader:\n",
        "\n",
        "      for i in range(4):\n",
        "        images[i] = images[i].to(DEVICE)\n",
        "      \n",
        "      labels = labels.to(DEVICE)\n",
        "\n",
        "      net.train() \n",
        "\n",
        "      optimizer.zero_grad() \n",
        "      \n",
        "      outputs = net(images)\n",
        "\n",
        "      loss = criterion(outputs, labels)\n",
        "      print(\"loss:{}\".format(loss.item()))\n",
        "\n",
        "      loss.backward()  \n",
        "      optimizer.step() \n",
        "\n",
        "      current_step += 1\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VsNFT9HwJcm-",
        "colab_type": "text"
      },
      "source": [
        "###**Test**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sz7DUMOHJed6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#net = net.to(DEVICE) \n",
        "net.train(False) # Set Network to evaluation mode , equivalent to net.eval()\n",
        "\n",
        "test_dataloader = DataLoader(dataset=test_dataset, batch_size=best_BS, shuffle=True, num_workers=4, drop_last=True)\n",
        "\n",
        "running_corrects = 0\n",
        "for images, labels in tqdm(test_dataloader): #evaluate performance on validation set\n",
        "  for i in range(4):\n",
        "      images[i] = images[i].to(DEVICE)\n",
        "  labels = labels.to(DEVICE)\n",
        "\n",
        "  # Forward Pass\n",
        "  outputs = net(images)\n",
        "  # Get predictions\n",
        "  _, preds = torch.max(outputs.data, 1)\n",
        "\n",
        "  # Update Corrects\n",
        "  running_corrects += torch.sum(preds == labels.data).data.item()\n",
        "\n",
        "# Calculate Accuracy on validation set\n",
        "accuracy = running_corrects / float(len(test_dataset))\n",
        "\n",
        "\n",
        "print('Test Accuracy: {}'.format(accuracy))\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EPyUsgphtlTM",
        "colab_type": "text"
      },
      "source": [
        "####**Data examples**\n",
        "Print some of the results."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wSGRs4BwtkQy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_img=30\n",
        "saved_outputs = torch.Tensor([256,4])\n",
        "saved_labels = torch.Tensor([256])\n",
        "saved_images = torch.Tensor([])\n",
        "\n",
        "def imshow(inp,ax, title=None):\n",
        "\n",
        "    \"\"\"Imshow for Tensor.\"\"\"\n",
        "    inp = inp.numpy().transpose((1, 2, 0))\n",
        "    mean = np.array([0.485, 0.456, 0.406])\n",
        "    std = np.array([0.229, 0.224, 0.225])\n",
        "    inp = std * inp + mean\n",
        "    inp = np.clip(inp, 0, 1)\n",
        "    ax.imshow(inp)\n",
        "\n",
        "def visualize(net, dataloader, num):\n",
        " \n",
        "  net.train(False)\n",
        "  fig = plt.figure(figsize=(15,7))\n",
        "  images_so_far = 0\n",
        "\n",
        "  for images,labels in dataloader:\n",
        "    saved_labels = labels\n",
        "    for i in range(4):\n",
        "      images[i] = images[i].to(DEVICE)\n",
        "    \n",
        "    labels = labels.to(DEVICE)\n",
        "\n",
        "    outputs = net(images)\n",
        "    saved_outputs = outputs\n",
        "    \n",
        "    _, preds = torch.max(outputs.data, 1)\n",
        "\n",
        "    for j in range(best_BS):\n",
        "      # uncomment the following line to print mislabeled images only\n",
        "      if dataset.classes[preds[j]] != dataset.classes[labels[j]]:       \n",
        "        images_so_far += 1\n",
        "        k=1\n",
        "        fig = plt.figure(figsize=(11,2))\n",
        "        for i in range (4) :\n",
        "          #ax = plt.subplot(1,4,k)\n",
        "          ax = fig.add_subplot(1,4,i+1)\n",
        "          ax.axis('off')\n",
        "          k += 1\n",
        "          imshow(images[i].cpu().data[j],ax) #\n",
        "        fig.suptitle('predicted: {} - real: {}'.format(dataset.classes[preds[j]],dataset.classes[labels[j]]))\n",
        "        plt.show()\n",
        "        print(\"\\n\")\n",
        "        if images_so_far == num:\n",
        "          return"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V5f5yMq9wKSt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tot_dataloader = DataLoader(dataset=test_dataset, batch_size=best_BS, shuffle=True, num_workers=4, drop_last=True)\n",
        "visualize(net,tot_dataloader,num_img)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}